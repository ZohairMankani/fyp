{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPp6YpUPe074"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install llama-index\n",
        "!pip install llama-index-llms-groq\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-parse\n",
        "!pip install nest_asyncio\n",
        "!pip install google-colab\n",
        "!pip install opencv-python\n",
        "!pip install fastapi uvicorn\n",
        "!pip install python-multipart\n",
        "!pip install spacy\n",
        "!pip install transformers\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import os\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core import Settings\n",
        "from transformers import pipeline\n",
        "import spacy\n",
        "import time\n",
        "import threading\n",
        "from google.colab import files\n",
        "\n",
        "# Apply asyncio patch\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Environment variables for API keys (replace with real keys)\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-U6JoUqhtKdQRwx20kGS8sy61gdozYI70EN8P5xWNq3nCNvFr\"\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "\n",
        "# Initialize LLM and embeddings\n",
        "llm = Groq(model=\"llama3-8b-8192\")\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "# Load the spaCy model for English\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load Hugging Face zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Labels for question classification\n",
        "labels = [\"harmful\", \"health benefits\", \"general ingredient question\"]\n",
        "\n",
        "# User profiles (stored in a JSON file)\n",
        "user_profiles_file = \"user_profiles.json\"\n",
        "\n",
        "# Load user profiles from JSON\n",
        "def load_user_profiles():\n",
        "    if os.path.exists(user_profiles_file):\n",
        "        with open(user_profiles_file, \"r\") as file:\n",
        "            return json.load(file)\n",
        "    return {}\n",
        "\n",
        "# Save user profiles to JSON\n",
        "def save_user_profiles(profiles):\n",
        "    with open(user_profiles_file, \"w\") as file:\n",
        "        json.dump(profiles, file)\n",
        "\n",
        "# Create or update user profile\n",
        "def create_or_update_profile(user_id, dietary_restrictions=None, preferences=None):\n",
        "    profiles = load_user_profiles()\n",
        "    profiles[user_id] = {\n",
        "        \"dietary_restrictions\": dietary_restrictions or profiles.get(user_id, {}).get(\"dietary_restrictions\", []),\n",
        "        \"preferences\": preferences or profiles.get(user_id, {}).get(\"preferences\", []),\n",
        "    }\n",
        "    save_user_profiles(profiles)\n",
        "    print(f\"Profile updated for user {user_id}: {profiles[user_id]}\")\n",
        "\n",
        "# Extract text from image using Tesseract\n",
        "def extract_text_from_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    extracted_text = pytesseract.image_to_string(gray)\n",
        "    return extracted_text\n",
        "\n",
        "# Improved Ingredient Extraction using regex and NLP techniques\n",
        "def extract_ingredients_from_text(extracted_text):\n",
        "    cleaned_text = re.sub(r\"[^a-zA-Z, ]+\", \"\", extracted_text).lower()\n",
        "    ingredients = [ingredient.strip() for ingredient in cleaned_text.split(\",\") if ingredient.strip()]\n",
        "    return ingredients\n",
        "\n",
        "# Recommend products based on ingredients and user preferences\n",
        "def recommend_products_based_on_ingredients(ingredients, user_profile):\n",
        "    # Placeholder: Implement your API interaction here\n",
        "    products = []  # Replace with actual API call to fetch products based on ingredients\n",
        "\n",
        "    recommendations = []\n",
        "    for product in products:\n",
        "        if any(allergen in product[\"ingredients\"] for allergen in user_profile.get(\"dietary_restrictions\", [])):\n",
        "            continue\n",
        "        if all(pref in product[\"tags\"] for pref in user_profile.get(\"preferences\", [])):\n",
        "            recommendations.append(product)\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Function to classify user queries using spaCy and Hugging Face\n",
        "def classify_user_query(user_question):\n",
        "    # Use spaCy to process the text\n",
        "    doc = nlp(user_question)\n",
        "\n",
        "    # Extract the entities (like ingredients or products)\n",
        "    entities = [ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"PRODUCT\"]]\n",
        "\n",
        "    # Classify the question using Hugging Face zero-shot classifier\n",
        "    result = classifier(user_question, candidate_labels=labels)\n",
        "\n",
        "    # Determine the highest-scoring label\n",
        "    classification = result[\"labels\"][0]\n",
        "    score = result[\"scores\"][0]\n",
        "\n",
        "    print(f\"Query classification: {classification} (Confidence: {score:.2f})\")\n",
        "\n",
        "    # Route the query based on the classification\n",
        "    if classification == \"harmful\":\n",
        "        return handle_harmful_question(entities)\n",
        "    elif classification == \"health benefits\":\n",
        "        return handle_health_benefits_question(entities)\n",
        "    else:\n",
        "        return handle_general_question(entities)\n",
        "\n",
        "# Define handlers for different types of questions\n",
        "def handle_harmful_question(entities):\n",
        "    if entities:\n",
        "        return f\"Checking whether {entities[0]} is harmful...\"\n",
        "    else:\n",
        "        return \"Please specify an ingredient you're asking about.\"\n",
        "\n",
        "def handle_health_benefits_question(entities):\n",
        "    if entities:\n",
        "        return f\"Here are some health benefits of {entities[0]}...\"\n",
        "    else:\n",
        "        return \"Please specify the ingredient you want to know the health benefits of.\"\n",
        "\n",
        "def handle_general_question(entities):\n",
        "    if entities:\n",
        "        return f\"Here's some general information about {entities[0]}...\"\n",
        "    else:\n",
        "        return \"Please specify the ingredient you're asking about.\"\n",
        "\n",
        "# Timeout decorator for user inactivity\n",
        "def timeout_input(prompt, timeout=600):\n",
        "    result = [None]\n",
        "\n",
        "    def input_with_timeout():\n",
        "        result[0] = input(prompt)\n",
        "\n",
        "    thread = threading.Thread(target=input_with_timeout)\n",
        "    thread.daemon = True\n",
        "    thread.start()\n",
        "    thread.join(timeout)\n",
        "\n",
        "    if thread.is_alive():\n",
        "        return None\n",
        "    return result[0]\n",
        "\n",
        "# Function for continuous chat with a basic chatbot\n",
        "def continuous_chat_with_basic_chatbot(extracted_text):\n",
        "    while True:\n",
        "        user_question = timeout_input(\"\\nYou: \")  # Get user input with a 10-minute timeout\n",
        "        if user_question is None:\n",
        "            print(\"\\nChat ended due to inactivity.\")\n",
        "            break\n",
        "        if user_question.lower() in [\"exit\", \"quit\", \"main\"]:\n",
        "            print(\"Returning to main menu.\")\n",
        "            break\n",
        "\n",
        "        # Classify the user question and route it to the appropriate handler\n",
        "        response = classify_user_query(user_question)\n",
        "        print(\"\\nIngredients Assistant: \", response)\n",
        "\n",
        "# Function for continuous chat with LLaMA (natural conversation)\n",
        "def continuous_chat_with_llama(extracted_text):\n",
        "    messages = [\n",
        "        ChatMessage(role=\"system\", content=\"You are an AI assistant who provides detailed information and has natural conversations.\"),\n",
        "        ChatMessage(role=\"user\", content=f\"Here is some extracted text: {extracted_text}. Can you explain what this is about?\")\n",
        "    ]\n",
        "\n",
        "    # Initial chat response from LLaMA\n",
        "    chat_response = llm.chat(messages)\n",
        "    print(\"\\nInitial Shopping Assistant Response:\\n\", chat_response)\n",
        "\n",
        "    while True:\n",
        "        user_question = timeout_input(\"\\nYou: \")  # Get user input with a 10-minute timeout\n",
        "        if user_question is None:\n",
        "            print(\"\\nChat ended due to inactivity.\")\n",
        "            break\n",
        "        if user_question.lower() in [\"exit\", \"quit\", \"main\"]:\n",
        "            print(\"Returning to main menu.\")\n",
        "            break\n",
        "\n",
        "        # Continue the conversation naturally with LLaMA\n",
        "        messages.append(ChatMessage(role=\"user\", content=user_question))\n",
        "        chat_response = llm.chat(messages)\n",
        "        print(\"\\nShopping: \", chat_response)\n",
        "\n",
        "# Main menu for chatbot selection\n",
        "def main_menu():\n",
        "    while True:\n",
        "        uploaded = files.upload()\n",
        "        user_id = input(\"Enter your user ID: \")\n",
        "\n",
        "        for fn in uploaded.keys():\n",
        "            extracted_text = extract_text_from_image(fn)\n",
        "            print(\"Extracted Text:\", extracted_text)\n",
        "\n",
        "            update_profile = input(\"Would you like to update your profile? (yes/no): \").lower()\n",
        "            if update_profile == \"yes\":\n",
        "                dietary_restrictions = input(\"Enter dietary restrictions (comma-separated): \").split(',')\n",
        "                preferences = input(\"Enter preferences (comma-separated): \").split(',')\n",
        "                create_or_update_profile(user_id, dietary_restrictions=dietary_restrictions, preferences=preferences)\n",
        "\n",
        "            # Provide user the option to choose between continuous chat with LLaMA or a basic chatbot\n",
        "            while True:\n",
        "                chat_option = input(\"Choose a chatbot option: (1) Ingredients Assistant (2) Shopping Assistant\\nEnter your choice (1, 2, or 'exit' to quit): \").strip()\n",
        "\n",
        "                if chat_option == \"1\":\n",
        "                    # Begin continuous chat with basic chatbot\n",
        "                    continuous_chat_with_basic_chatbot(extracted_text)\n",
        "                elif chat_option == \"2\":\n",
        "                    # Begin continuous chat with LLaMA\n",
        "                    continuous_chat_with_llama(extracted_text)\n",
        "                elif chat_option.lower() == \"exit\":\n",
        "                    print(\"Exiting program.\")\n",
        "                    return\n",
        "                else:\n",
        "                    print(\"Invalid choice! Please try again. To Go Back to Main Menu Enter 'main'\")\n",
        "\n",
        "# Run the main menu function\n",
        "main_menu()\n"
      ],
      "metadata": {
        "id": "c3Ixgb4se-30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}